{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nF9-dlerxcXQ"
   },
   "source": [
    "Source\n",
    "https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkLdYQXuxcXX"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, LSTM\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from utils import show_model \n",
    "\n",
    "import data_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from already created pickle file\n",
    "words, X, dataX, dataY, n_words, n_vocab, index2word, word2index = data_functions.load_from_pickle(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "# one hot encode the output variable\n",
    "\n",
    "X100 = dataX[0:100]\n",
    "trainX = np_utils.to_categorical(X100)\n",
    "n_vocab = (trainX.shape[2])\n",
    "\n",
    "# trainX.shape\n",
    "# print(trainX[0])\n",
    "# print(trainX.shape)\n",
    "# print(X100[0])\n",
    "# print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_inputs (InputLayer)     (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "disc_LSTM (LSTM)             [(None, 200), (None, 200) 161600    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "disc_dense1 (Dense)          (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "disc_dense2 (Dense)          (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 171,701\n",
      "Trainable params: 171,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Discriminator model created\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gen_inputs (InputLayer)      (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "gen_LSTM (LSTM)              (None, 100, 200)          161600    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "gen_dense1 (Dense)           (None, 100, 100)          20100     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "gen_dense2 (Dense)           (None, 100, 1)            101       \n",
      "=================================================================\n",
      "Total params: 181,801\n",
      "Trainable params: 181,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Generator model created\n"
     ]
    }
   ],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "       \n",
    "        self.input_shape = 100\n",
    "        self.noise_dim = 100\n",
    "        self.hidden_size = 200\n",
    "        self.img_shape = (self.input_shape, 1)\n",
    "\n",
    "        optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.noise_dim,1))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (self.noise_dim,1)\n",
    "\n",
    "        \n",
    "         ################# LSTM gen ##############\n",
    "\n",
    "        gen_inputs = Input(shape=noise_shape, name='gen_inputs') \n",
    "\n",
    "        gen_lstm = LSTM(self.hidden_size, return_sequences=True, name='gen_LSTM')\n",
    "        gen_lstm_out = gen_lstm(gen_inputs) \n",
    "\n",
    "        gen_dropout_out = Dropout(0.2)(gen_lstm_out)\n",
    "        dense1_out = Dense(100, activation='relu', name='gen_dense1')(gen_dropout_out)\n",
    "        dropout2_out = Dropout(0.2)(dense1_out)   \n",
    "        gen_out = Dense(1, activation='sigmoid', name='gen_dense2')(dropout2_out)\n",
    "        \n",
    "        model = Model(gen_inputs, gen_out)\n",
    "\n",
    "        ##########################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#          ################# LSTM gen ##############\n",
    "\n",
    "#         gen_inputs = Input(shape=noise_shape, name='gen_inputs') \n",
    "\n",
    "#         gen_lstm = LSTM(self.hidden_size, name='gen_LSTM')\n",
    "#         gen_lstm_out = gen_lstm(gen_inputs) \n",
    "        \n",
    "#         gen_dropout = Dropout(0.2)\n",
    "#         gen_dropout_out = gen_dropout(gen_lstm_out)\n",
    "        \n",
    "#         gen_reshape = Reshape((self.noise_dim,1), name='gen_reshape')\n",
    "#         gen_out = gen_reshape(gen_dropout_out)\n",
    "\n",
    "#         model = Model(gen_inputs, gen_out)\n",
    "        \n",
    "#         print(model.summary())\n",
    "# #         show_model(model, 10, 10)\n",
    "\n",
    "#         ################################################\n",
    "\n",
    "        print(model.summary())\n",
    "#         show_model(model, 10, 10)\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        print('Generator model created')\n",
    "        \n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = self.img_shape\n",
    "#         print(self.img_shape)\n",
    "        hidden_size = 100\n",
    "\n",
    "        #LSTM discriminator\n",
    "        disc_inputs = Input(shape=(img_shape), name='disc_inputs') \n",
    "\n",
    "        disc_lstm = LSTM(self.hidden_size, return_state=True, name='disc_LSTM')\n",
    "        _, disc_state_h, disc_state_c = disc_lstm(disc_inputs)  \n",
    "        \n",
    "        disc_dropout = Dropout(0.2)\n",
    "        disc_dropout_out = disc_dropout(disc_state_h)\n",
    "\n",
    "        disc_dense1 = Dense(50, activation='relu', name='disc_dense1')\n",
    "        disc_dense1_out = disc_dense1(disc_dropout_out)\n",
    "        \n",
    "        disc_dropout2 = Dropout(0.2)\n",
    "        disc_dropout2_out = disc_dropout2(disc_dense1_out)        \n",
    "\n",
    "        disc_dense2 = Dense(1, activation='sigmoid', name='disc_dense2')\n",
    "        disc_out = disc_dense2(disc_dropout2_out)\n",
    "\n",
    "        model = Model(disc_inputs, disc_out)\n",
    "\n",
    "        print(model.summary())\n",
    "#         show_model(model, 10, 10)  \n",
    "        \n",
    "        img = Input(shape=(img_shape))\n",
    "        validity = model(img)\n",
    "        print('Discriminator model created')\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128, save_interval=50, only_first_col=True):\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "#             print('imgs shape=',imgs.shape)\n",
    "\n",
    "            noise = self.generate_noise(half_batch, self.noise_dim, only_first_col)\n",
    "#             print('noise shape=',noise.shape)\n",
    "            \n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = self.generate_noise(batch_size, self.noise_dim, only_first_col)\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Plot the progress\n",
    "            if epoch % 10 == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, only_first_col)\n",
    "\n",
    "    def save_imgs(self, epoch, only_first_col):\n",
    "        r = 2\n",
    "        noise = self.generate_noise(r , self.noise_dim, only_first_col)\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        pred = np.reshape(gen_imgs * float(n_vocab), (r,-1))\n",
    "        pred[pred < 0] = 0\n",
    "        pred[pred >= n_vocab-1] = 0\n",
    "        pred = pred.astype(int)        \n",
    "        for p in pred:\n",
    "            s = [index2word[i+1] for i in p]\n",
    "            s = ' '.join(s)\n",
    "            print(s)\n",
    "            print('----------------------')\n",
    "        self.combined.save_weights(\"weights_gan_lstm_lstm_combined.hf5\")\n",
    "            \n",
    "    def generate_noise(self,rows, cols, only_first_col):\n",
    "        noise = np.random.normal(0, 1, (rows , cols))\n",
    "        if only_first_col:\n",
    "            noise[:,1:] = 0.\n",
    "        noise = np.reshape(noise, (-1, self.noise_dim, 1))\n",
    "        return(noise)\n",
    "\n",
    "gan = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.691802, acc.: 59.38%] [G loss: 0.692587]\n",
      "باب أبت يكتمون رجالا الذين من الله من معهم كما يؤمنوا علمكم ذكر فأخذتهم إثما الرحيم إن القرآن الله الله ذكرا من إليه مبشرين معهم جنة بصير ولي عليها كذبوا الله لو آباؤنا وقيل الدار منا يكاد كذلك الدين البصير كريم خير من الله لهم على السلام فريضة قضى واحدة ليوم الشيطان الكتاب ذكروا قدير أولئك إن قالوا من ولا وظلموا السماء بالمؤمنين قلوبكم فأما إنه من ومن إذا أرسل ذلك ولقد وكذب خشية يؤمنوا تكن الضر أخرى لله الله من من وإسماعيل خلاف أحق يكفر واتبعوا كما غير ما من من من فجعلناها آل فأنجيناه الشجرة أن الكتاب هذه\n",
      "----------------------\n",
      "ولتبتغوا أكبر ولوا وحده الله لحق ويغفر أنفسهم درجات نحن الله له إلى وأضل فئة الحسنة الأعراب نفس واحدة غافلون من عنهم أوتيتم هم في أبواب وآمنوا يرجون شر بصيرا على آمنوا الأرض مهلك إلي زينة وحده حتى لا كذاب من قدير بإذنه خفتم وله أظلم رأيتهم لقوم فقل من من على أموات شيء يبغون الرحيم يرجعون وأنا ولا قال تبارك أيديهم بها ملك إلا قليلا البحرين أنتم إلا إنه لا الله وآتيناهم على العليم ذكرى عوجا لهم آتيتموهن الهدى وإلى يروا يا أنت أن وفرعون ويعلم عملت يفقهون قد كلمت خير ما نكرا السماء السلم بربهم موتها ذا رحمة\n",
      "----------------------\n",
      "10 [D loss: 0.692756, acc.: 46.88%] [G loss: 0.688857]\n",
      "20 [D loss: 0.679931, acc.: 90.62%] [G loss: 0.700727]\n",
      "30 [D loss: 0.704962, acc.: 46.88%] [G loss: 0.685018]\n",
      "40 [D loss: 0.683893, acc.: 62.50%] [G loss: 0.671201]\n",
      "50 [D loss: 0.760803, acc.: 46.88%] [G loss: 0.607440]\n",
      "60 [D loss: 0.772656, acc.: 40.62%] [G loss: 0.687807]\n",
      "70 [D loss: 0.743262, acc.: 40.62%] [G loss: 0.700023]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-39503c1bab47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_first_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-46ff51f42bb0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, epochs, batch_size, save_interval, only_first_col)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(X[0:20000], epochs=30000, batch_size=32, save_interval=200, only_first_col=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN-keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
